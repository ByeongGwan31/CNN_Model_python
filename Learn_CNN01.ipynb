{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOiayNekeGA2SEgwUUyBWhZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RN6-dDRG42Rt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707029719148,"user_tz":-540,"elapsed":20458,"user":{"displayName":"강병관","userId":"15477357221876048109"}},"outputId":"f4a10826-f6ac-472a-bac5-4bdb8abe004b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","import matplotlib.pyplot as plt\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader"],"metadata":{"id":"wsewl7mM5hTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# [2]번줄 코드 해석 :\n","# MNIST라는 숫자 데이터셋을 다운받기 위하여, torchvison 이라는 라이브러를 미리 다운로드 한다.\n","# 가지고 있는 데이터의 순서를 섞거나 원하는 비율로 나누거나 하는 데이터를 전처리르 위해 DataLoader를 선언한다."],"metadata":{"id":"NMHxC9bC6LG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 256\n","\n","learning_rate = 0.0002\n","\n","num_epoch = 10"],"metadata":{"id":"y5MGxajL6YEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN에서 batch_size는 한번에 학습하는 이미지의 수이다. 즉, MNIST는 6만장의 데이터가 있고,\n","# 이걸 한장한장씩 학습하는 것이 아닌,ㄴ 256개씩 묶어서 진행하겠다는 뜻이다. (256개가 아니어도 된다.)\n","# 6만장의 사진을 학습하므로, learning rate는 조금 낮은 값으로 잡는것이 발산할 수 있는 가능성을 낮추어준다.\n","\n","# 데이터의 사이즈가 큰 관계로 epoch는 10번만 해준다."],"metadata":{"id":"5kORVIcN6cjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_train = dset.MNIST(\"./\",train=True, transform = transforms.ToTensor(), target_transform=None, download = True)\n","\n","mnist_test = dset.MNIST(\"./\", train=False, transform = transforms.ToTensor(), target_transform=None, download = True)\n","\n","# torchvision.datasets 라이브러리에서 MNIST 데이터를 받아오는 코드"],"metadata":{"id":"WkdnXD9z7NAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n","\n","test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)\n","\n","# 받아온 데이터를 학습하기 위해 나누어준다.\n","# bath_size 선언, shuffle : 데이터를 무작위로 섞을 때\n","# num_workers : 데이터를 묶을 때 사용하는 프로세스 갯수\n","# drop_last : 묶고 남은 자투리 데이터들을 버릴지 말지"],"metadata":{"id":"MzGJfIVF95wg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","\n","    #C++에서 사용되는 Class 선언(파이썬 : 객체지향 언어)\n","\n","    def __init__(self) :\n","\n","        super(CNN,self).__init__() #Super class로 지금 작성하고있는 클래스 자체를 초기화하기 위함\n","\n","        self.layer = nn.Sequential(\n","\n","            nn.Conv2d(1,16,5),\n","\n","            nn.ReLU(),\n","\n","            nn.Conv2d(16,32,5),\n","\n","            nn.ReLU(),\n","\n","            nn.MaxPool2d(2,2),\n","\n","            nn.Conv2d(32,64,5),\n","\n","            nn.ReLU(),\n","\n","            nn.MaxPool2d(2,2)\n","\n","        )\n","\n","        #Conv2d : Convolution Filtering이라는 Signal Processing적인 방법으로 이미지를 처리 하는것으로,\n","\n","        #nn.Conv2d(1,16,5)는 1개필터짜리 입력(28x28 해상도의 이미지, default filter 갯수 = 1)을 받아 16개의 필터로 size 5의 Kernel(Filtering)을 하는것입니다.\n","\n","        #기본적으로 CNN은 신호/영상처리에 대한 기본적인 이해가 있어야합니다.\n","\n","        #Kernel size가 5인경우, Convoltuion을 하게 되면 4개의 pixel이 사라지게 되어(28x28)의 input 이미지가 (24x24)가 됩니다.\n","\n","        #이런식으로 이미지의 사이즈를 줄여가며 강한 특징만을 추려나가는게 CNN입니다.\n","\n","\n","\n","        #MaxPooling을 중간중간 섞어줌으로써, Convolution보다 더욱 강하게 Feature들을 뽑아내줍니다.\n","\n","        self.fc_layer = nn.Sequential(\n","\n","            nn.Linear(64*3*3,100),\n","\n","            nn.ReLU(),\n","\n","            nn.Linear(100,10)\n","\n","        )\n","\n","        #self.layer : CNN이 끝난 이후, 최종적으로 나오는 결과물은 [batch_size,64,3,3]입니다.\n","\n","        #즉, 256개의 이미지 묶음씩 64개의 필터, (3x3)의 이미지가 남게 되는것으로, pixel갯수로 따지면 64*3*3이 나오게 되는것입니다.\n","\n","        #따라서, 64*3*3의 결과값을 nn.Linear(100,10)을 통해 최종적으로 10개의 값이 나오게하는데\n","\n","        #이 10개의 값이 내가 넣은 이미지가 0~9(10개)중 어떤것일지에 대한 각각의 확률입니다.\n","\n","    def forward(self,x):\n","\n","        out = self.layer(x)\n","\n","        out = out.view(batch_size, -1)\n","\n","        out = self.fc_layer(out)\n","\n","        return out\n","\n","        #CNN함수의 전체적인 그림으로, Conv2d -> Linear Regression -> 추정 입니다.\n","\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","  #이부분은 굳이 안해주셔도 됩니다. GPU를 사용할 수 없는경우 CPU를 쓰겠다는 것으로, 이부분을 주석처리하고\n","\n","  # model = CNN()로만 해주셔도 됩니다.\n","\n","model = CNN().to(device)\n","\n","loss_func = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","\n","#Cross Entropy Loss function, Adam optimizer\n","\n","\n","\n","loss_arr = []\n","\n","for i in range(num_epoch):\n","\n","    for j,[image,label] in enumerate(train_loader):\n","\n","        x = image.to(device)\n","\n","        #mnist 학습용 data를 불러옵니다.(28x28)\n","\n","        y_ = label.to(device)\n","\n","        #각각의 data들이 0~9중 어떤숫자인지도 불러옵니다.\n","\n","        optimizer.zero_grad()\n","\n","        #optimizer 초기화\n","\n","        output = model.forward(x)\n","\n","        #학습용 데이터로 CNN 실시\n","\n","        loss = loss_func(output,y_)\n","\n","        #학습해서 추정해낸 값과, 실제 라벨된 값 비교\n","\n","        loss.backward()\n","\n","        #오차만큼 다시 Back Propagation 시행\n","\n","        optimizer.step()\n","\n","        #Back Propagation시 ADAM optimizer 매 Step마다 시행\n","\n","        if j % 1000 == 0 :\n","\n","            print(loss)\n","\n","            loss_arr.append(loss.cpu().detach().numpy())\n","\n","\n","\n","correct = 0\n","\n","total = 0\n","\n","with torch.no_grad():\n","\n","    for image,label in test_loader :\n","\n","        x = image.to(device)\n","\n","        y_ = label.to(device)\n","\n","\n","\n","        output = model.forward(x)\n","\n","        _,output_index = torch.max(output,1)\n","\n","\n","\n","        total += label.size(0)\n","\n","        correct += (output_index == y_).sum().float()\n","\n","\n","\n","    print(\"Accuracy of Test Data : {}\".format(100*correct/total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSNl1Nle-oTc","executionInfo":{"status":"ok","timestamp":1707032850586,"user_tz":-540,"elapsed":798955,"user":{"displayName":"강병관","userId":"15477357221876048109"}},"outputId":"a73aadec-577e-4c2a-d5aa-22e671efb71a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3037, grad_fn=<NllLossBackward0>)\n","tensor(0.2792, grad_fn=<NllLossBackward0>)\n","tensor(0.1016, grad_fn=<NllLossBackward0>)\n","tensor(0.1267, grad_fn=<NllLossBackward0>)\n","tensor(0.0552, grad_fn=<NllLossBackward0>)\n","tensor(0.0928, grad_fn=<NllLossBackward0>)\n","tensor(0.0588, grad_fn=<NllLossBackward0>)\n","tensor(0.0759, grad_fn=<NllLossBackward0>)\n","tensor(0.0192, grad_fn=<NllLossBackward0>)\n","tensor(0.0562, grad_fn=<NllLossBackward0>)\n","Accuracy of Test Data : 98.6278076171875\n"]}]},{"cell_type":"code","source":["# 해석 : Train Data로 학습시키고, Test Dataset으로 검증하면,\n","# 약 98.66%의 정확도로 사진의 숫자를 추정하는 것을 확인 할 수 있다."],"metadata":{"id":"fB6oA9Sb_EGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Google Colab/CNN_Model_python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59LzwwHvGcNG","executionInfo":{"status":"ok","timestamp":1707033555854,"user_tz":-540,"elapsed":344,"user":{"displayName":"강병관","userId":"15477357221876048109"}},"outputId":"a551a755-e8b1-4b32-e275-b6a03a007b32"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Google Colab/CNN_Model_python\n"]}]},{"cell_type":"code","source":["!git config --global user.email '2000bk@naver.com'\n","!git config --global user.name 'ByeongGwan31'"],"metadata":{"id":"uPJaBruj_OkI","executionInfo":{"status":"ok","timestamp":1707033559468,"user_tz":-540,"elapsed":858,"user":{"displayName":"강병관","userId":"15477357221876048109"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["!git add Learn_CNN01.ipynb"],"metadata":{"id":"WnIPvJYkGV7W","executionInfo":{"status":"ok","timestamp":1707033563765,"user_tz":-540,"elapsed":2411,"user":{"displayName":"강병관","userId":"15477357221876048109"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["!git commit -m '2024_02_04 합성곱신경망 CNN 코드 공부 ② 실습 완료 해석하기중...'\n","!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TByBtTEHGXs_","executionInfo":{"status":"ok","timestamp":1707033573569,"user_tz":-540,"elapsed":6543,"user":{"displayName":"강병관","userId":"15477357221876048109"}},"outputId":"fa376057-376b-45e3-d522-0ca0b5ee44f6"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch and 'origin/main' have diverged,\n","and have 3 and 1 different commits each, respectively.\n","  (use \"git pull\" to merge the remote branch into yours)\n","\n","It took 2.27 seconds to compute the branch ahead/behind values.\n","You can use '--no-ahead-behind' to avoid this.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   Advance_CNN.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","To https://github.com/ByeongGwan31/CNN_Model_python.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://github.com/ByeongGwan31/CNN_Model_python.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HI6aIxkRGalf"},"execution_count":null,"outputs":[]}]}